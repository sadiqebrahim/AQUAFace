<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="AQUAFace improves face recognition under age and quality variations enhancing selfie vs. ID matching">
  <meta name="keywords" content="AQUAFace">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AQUAFace</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">AQUAFace: Age-Invariant Quality Adaptive Face Recognition for Unconstrained
            Selfie vs ID Verification</h1>
          <h2 style="font-size: 1.5em; color: dimgray; margin-bottom: .5em; margin-top: -.5em;">AAAI 2025
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Shivang Agarwal</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Jyoti Chaudhary</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Sadiq Siraj Ebrahim</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Mayank Vatsa</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Richa Singh</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Shyam Prasad Adhikari</a><sup>1,3</sup>,
            </span>
            <span class="author-block">
              <a href="">Sangeeth Reddy Battu</a><sup>3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington,</span>
            <span class="author-block"><sup>2</sup>Google Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/sadiqebrahim/AQUAFace"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <img src="./static/images/faces.jpeg" alt="" border="0" height="300" width="750">
            <div class="content has-text-justified">
                <p>Figure 1. Examples of image pairs depicting variations in age, quality, and combined age + quality factors. 
                  The top row illustrates easy pairs with high recognizability, the middle row depicts pairs of medium 
                  difficulty in recognition, and the bottom row showcases hard pairs posing challenges in verification. 
                  It is evident that the combined effect of age and quality variations notably reduces recognizability.
                </p>
              <h2 class="title is-3 is-centered">Abstract</h2>
              <!-- <img src="./static/images/visual_abstract.png" alt="" border="0" height="300" width="750">
                  <p>Figure 2. The proposed PETAL<i>face</i>: a parameter efficient transfer learning approach
                      adapts to low-resolution datasets
                      beating the performance of pre-trained models with negligible drop in performance on
                      high-resolution and mixed-quality
                      datasets. PETAL<i>face</i> enables development of generalized models achieving competitive
                      performance on
                      high-resolution (LFW, CFP-FP, CPLFW, AgeDB, CALFW, CFP-FF) and mixed-quality datasets
                      (IJB-B, IJB-C) with big
                      enhancements in low-quality surveillance quality datasets (TinyFace, BRIAR, IJB-S)
                  </p> -->
                  <p>
                    Face recognition in the presence of age and quality variations
                    poses a formidable challenge. While recent margin-based
                    loss functions have shown promise in addressing these variations individually, real-world scenarios such as selfie versus ID face matching often involve simultaneous variations
                    of both age and quality. In response, we propose a comprehensive framework aimed at mitigating the impact of these
                    variations while preserving vital identity-related information
                    crucial for accurate face recognition. The proposed adaptive
                    margin-based loss function AQUAFace exhibits adaptiveness
                    towards hard samples characterized by significant age and
                    quality variations. This loss function is meticulously designed
                    to prioritize the preservation of identity-related features while
                    simultaneously mitigating the adverse effects of age and quality variations on face recognition accuracy. To validate the
                    effectiveness of our approach, we focus on the specific task
                    of selfie versus ID document matching. Our results demonstrate that AQUAFace effectively handles age and quality differences, leading to enhanced recognition performance. Additionally, we explore the benefits of fine-tuning the recognition model with synthetic data, further boosting performance.
                    As a result, our proposed model, AQUAFace, achieves stateof-the-art performance on six benchmark datasets (CALFW,
                    CPLFW, CFP-FP, AgeDB, IJB-C, and TinyFace), each exhibiting diverse age and quality variations.
                  </p>
              </div>
          </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->

      <section class="section">
          <div class="container is-max-desktop">
              <!-- Abstract. -->
              <div class="columns is-centered has-text-centered">
                  <div class="column is-four-fifths">
                      <h2 class="title is-3">AQUAFace Framework</h2>
                      <div class="content has-text-justified">
                          <h5 class="subtitle has-text-centered"></h5>

                          <img src="./static/images/model.jpeg" alt="" border="0" height="300" width="750">
                          <!-- <div class="content has-text-justified"> -->
                          <p>Overview of the proposed AQUAFace model: We have introduces a novel adaptive margin-based loss for 
                            age-invariant, quality-aware face recognition, specifically targeting selfie vs. ID verification tasks. 
                            It comprises three key components:
                          </p>
                          <ol>
                            <li><b>AQUALR</b>: A Gaussian Mixture Model (GMM)-based module computes an Age and Quality Likelihood 
                              Ratio (AQUALR), integrating age and quality labels into pairwise similarity scores. This enables 
                              dynamic sample weighting based on age and quality variations.
                            </li>
                            
                            <li><b>Adaptive Contrastive Loss</b>: The loss dynamically adjusts margins using AQUALR to penalize 
                              harder samples characterized by large age differences or low quality, enhancing intra-class 
                              compactness and inter-class separation. 
                            
                            <li><b>Identity Preservation</b>: A fine-tuned ArcFace model ensures robust identity-related 
                              feature extraction, utilizing margin-based softmax loss to maintain discriminative power under diverse variations.  
                            
                            The combined loss function integrates these components to optimize for both identity preservation and resilience against 
                            age and quality changes. The framework incorporates real and synthetic datasets for training, using synthetic data 
                            fine-tuning to enrich intra-class variability. The architecture leverages a Siamese network with shared weights 
                            and cosine similarity for feature comparison, achieving state-of-the-art performance across benchmark datasets.
                          </p>


                      </div>
                  </div>
              </div>
          </div>
      </section>

      <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Dataset</h2>
                    <div class="content has-text-justified">
                        <h5 class="subtitle has-text-centered"></h5>
                        <p>A synthetic dataset comprising 14,017 subjects was created by utilizing single images of each identity from the 
                          AgeDB and MORPH datasets. The Lifespan Age Transformation Synthesis (LATS) model (Or-El et al., 2020) was employed 
                          to generate age-transformed images at three target age ranges: 15-19, 30-35, and 50-65. To mimic real-world scenarios, 
                          these synthetic images underwent quality degradation using an algorithm similar to GFPGAN (Wang et al., 2021), 
                          introducing variations in image quality. As a result, the synthetic images exhibit significant differences from 
                          the original images in both quality and age.
                        </p>
        
                    </div>
                    <div class="content has-text-justified">
                        <h5 class="subtitle has-text-centered"></h5>
                        <img src="./static/images/morph.jpeg" alt="" border="0" height="300" width="750">
                        <img src="./static/images/agedb.jpeg" alt="" border="0" height="300" width="750">
                        <!-- <div class="content has-text-justified"> -->
                        <p>Figure 2: Samples of AgeDB and MORPH datasets along with their synthesized counterparts.
                          
                        </p>
        
                    </div>
                </div>
            </div>
        </div>
</div>
</section>

      <section class="section">
          <div class="container is-max-desktop">
              <div class="columns is-centered has-text-centered">
                  <div class="column is-four-fifths">
                      <h2 class="title is-3">Results</h2>
                      <div class="content has-text-justified">
                          <h5 class="subtitle has-text-centered"></h5>
                          <img src="./static/images/table1.jpeg" alt="" border="0" height="300" width="750">
                          <!-- <div class="content has-text-justified"> -->
                          <p>Table 1: Performance evaluation of various face verification models on Real (VerifyMe) and Synthetic (Syn AM) datasets after
                            bin-wise partitioning. We report GAR@0.1%FAR and GAR@1%FAR in easy, medium and hard categories.
                          </p>
          
                      </div>
                      <div class="content has-text-justified">
                          <h5 class="subtitle has-text-centered"></h5>
                          <img src="./static/images/table2.jpeg" alt="" border="0" height="300" width="750">
                          <!-- <div class="content has-text-justified"> -->
                          <p>Table 2: Performance comparison of recent methods on benchmark datasets with the AQUAFace model for ResNet100 and
                            ResNe18 backbone. For high quality datasets, 1:1 verification accuracy is reported, following the protocol from (Kim, Jain,
                            and Liu 2022). For mixed quality datasets, TAR@FAR=0.01% is reported. For TinyFace, closed-set rank retrieval (Rank-1 and
                            Rank-5) is reported. Note: The performance of the pretrained models on MS1MV2 is sourced from their respective papers.
                          </p>
                      <div class="content has-text-justified">
                        <h5 class="subtitle has-text-centered"></h5>
                        <img src="./static/images/table3.jpeg" alt="" border="0" height="300" width="750">
                        <!-- <div class="content has-text-justified"> -->
                        <p>Table 3: Comparison on benchmark datasets with the AQUAFace model trained on different data types. The first row represents
                          the model trained on real data (VerifyMe). The second row shows the model trained on the synthetic AgeDB and Morph
                          datasets. The last row presents the model's performance when trained on VerifyMe and fine-tuned on the synthetic AgeDB and
                          Morph. 1:1 verification accuracy is reported, following the protocol from (Kim, Jain, and Liu 2022)
                        </p>
          
                      </div>
          
                      </div>
                  </div>
              </div>
          </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>



</body>
</html>
